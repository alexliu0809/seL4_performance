\subsection{CPU, Scheduling, and OS Services}
We report on our results below.
\subsubsection{Measurement Overhead}
We performed ten rounds of experiments, with each round sampling the measurement overhead 100,000 times. We only report the average overhead across 100,000 samples for each round.
Table \ref{tab:t1} shows the average overhead across ten rounds. 
The results are very consistent.
All ten experiments got an average measurement overhead of 31 cycles.

Since this benchmark is just running two RDTSCP instructions in a row,
with some minimal moves inserted to copy the results (which may be
renamed away), we should expect that the number we get is quite close
to the issue latency of the RDTSCP.
%
Although Intel doesn't document the likely issue latency of RDTSCP,
Agner Fog's excellent X86 instruction latency tables show issue
latencies of 30-odd cycles for RDTSCP in similar microarchitectures
(Broadwell and Skylake), so this number seems reasonable.

\begin{table}[htb]

\caption{Mean, min and max values of average measurement overhead for ten rounds}

    \begin{tabular}{|c|c|c|c|} 
     \hline
     Mean & Min & Max & Stddev\\ 
     \hline
     31 & 31 & 31 & 0\\ 
     \hline
    \end{tabular}
    \label{tab:t1}
\end{table}

\subsubsection{Call Overhead}
For each number of arguments, we performed ten rounds of experiments,
with each round sampling the overhead 100,000 times.
%
We only report the average overhead across 100,000 samples for each
round.
%
Table \ref{tab:t2} shows the average overhead for ten rounds for each
function.
%
We see the average overhead increases with the number of args. We also
observe that most of the time, the average overhead is stable.
%

This benchmark again is only a few instructions, so it makes sense
that the latencies are generally quite stable.
%
The setup instructions necessary to put arguments in the correct
registers increase for each subsequent argument added, so small
increases in latency are to be expected.
%
For our benchmark, these are simple move-immediate instructions, so it
seems that the details of pipeline scheduling introduce variations of
a few cycles, allowing for adding an argument to sometimes not
noticeably increase latency.

\begin{table}[htb]

\caption{Mean, min and max values of average call overhead for ten rounds}

    \begin{tabular}{|c|c|c|c|c|} 
     \hline
     \# of Args & Mean & Min & Max & Stddev \\ 
     \hline
     0 & 34 & 34 & 34 & 0 \\ 
     \hline
     1 & 34 & 34 & 34 & 0\\ 
     \hline
     2 & 36 & 36 & 36 & 0\\ 
     \hline
     3 & 36.7 & 36 & 39 & 1.02\\ 
     \hline
     4 & 39 & 39 & 39 & 0\\ 
     \hline
     5 & 40 & 40 & 40 & 0\\ 
     \hline
     6 & 41.2 & 40 & 43 & 0.75 \\ 
     \hline
     7 & 42.9 & 42 & 43 & 0.30\\ 
     \hline
    \end{tabular}
    \label{tab:t2}
\end{table}


\subsubsection{Syscall Overhead}
We performed ten rounds of experiments, with each round sampling the
overhead 100,000 times.
%
We only report the average overhead across 100,000 samples for each
round.
%
Table \ref{tab:t3} shows the average and standard deviation for the
syscall overhead over the ten rounds.

It is difficult to predict the syscall overhead without simply
measuring it, because the details of syscall entry points in X64 are
complicated, and depend significantly on how the OS entry points work
(e.g. latency of switching stacks to the kernel stack).
%
The number of some 1700 cycles seems reasonable, as it shows latency
about two orders of magnitude worse than function calls for a full
kernel entry and exit.

\begin{table}[tb]

    \caption{Mean, min and max values of syscall overhead for ten rounds}
    
    \begin{tabular}{|c|c|c|c|} 
        \hline
        Mean & Min & Max & Stddev\\ 
        \hline
        1681.3 & 1678 & 1699 & 5.98\\ 
        \hline
       \end{tabular}
        \label{tab:t3}
\end{table}

    
\subsubsection{Task Creation Time}
\label{subsubsec:tct}
We performed ten rounds of experiments, with each round sampling the
overhead 100,000 times. %
We only report the average overhead across 100,000 samples for each
round. %
Table \ref{tab:t4} shows the average and standard deviation of task
creation time for the ten rounds. %
We observed some obvious outliers in this case, where the timestamp
counter appeared to move backwards. %
However, we are not able to explain what happened. %
This contributes to the unreasonably large standard deviation in the
table. %
We intend to run these benchmarks again with the outliers due to
backwards-moving timestamp counters removed. %

It is difficult to predict what task creation time should look like,
since a significant number of syscalls are needed to set up the new
thread's thread control block, as well as some userspace time needed
to allocate memory for the TCB, etc.
%
We see 9 or so syscall instructions in the generated assembly, so
latency about an order of magnitude worse than one syscall overhead is
reasonable.

\begin{table}[htb]

    \caption{Mean, min and max values of task creation time for ten rounds}
\begin{tabular}{|c|c|c|c|} 
    \hline
    Mean & Min & Max & Stddev\\ 
    \hline
    67620.9 & 24655 & 454173 & 128850.70\\ 
    \hline
   \end{tabular}
    \label{tab:t4}
\end{table}

\subsubsection{Task Switch Time}
We performed ten rounds of experiments, with each round sampling the
overhead 100,000 times. %
We only report the average overhead across 100,000 samples for each
round. %
Table \ref{tab:t5} shows the average and standard deviation of the
task switch time over the ten rounds. %
As with section~\ref{subsubsec:tct}, we observed some outliers, but
were unable to explain their cause, and intend to filter them out from
the dataset in the next round of experiments.

If the syscall overhead numbers from Table~\ref{tab:t3} represent two
CPU context switches (once from user-space to kernel-space and once
back), then switching to a new thread seems to take about three
context switches of time, which seems reasonable, since the scheduler
must use some time to find which thread is next to run.
%
Memory remapping is not needed, since the new thread is running in the
same address space as the original, so it makes sense that the context
switch takes the same order of magnitude time as a single syscall.
%


\begin{table}[htb]

    \caption{Mean, min and max values of task switch time for ten rounds}
 
\begin{tabular}{|c|c|c|c|} 
    \hline
    Mean & Min & Max & Stddev\\ 
    \hline
    6458.8 & 2158 & 45110 & 12883.74\\ 
    \hline
   \end{tabular}
    \label{tab:t5}
\end{table}
